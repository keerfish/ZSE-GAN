{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "import numpy\n",
    "from PIL import Image\n",
    "from torch.nn.modules.utils import _ntuple\n",
    "import datetime\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "import os , itertools\n",
    "\n",
    "from numpy import load\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "data_dir29 ='./dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':1,\n",
    "    'input_size':128,\n",
    "    'stack_num':29,\n",
    "    'resize':128,\n",
    "    'crop_size':32,\n",
    "    'fliplr':True,\n",
    "    'num_epochs':100,\n",
    "    'decay_epoch':100,\n",
    "    'save_epoch': 80,\n",
    "    'print_layer':1,\n",
    "    'ngf':16,               #number of generator filters\n",
    "    'ndf':32,               #number of discriminator filters\n",
    "    'num_resnet':6,         #number of resnet blocks\n",
    "    'lrG':0.0002,           #learning rate for generator\n",
    "    'lrD':0.0002,           #learning rate for discriminator\n",
    "    'beta1':0.5 ,           #beta1 for Adam optimizer\n",
    "    'beta2':0.999 ,         #beta2 for Adam optimizer\n",
    "    'lambdaA':10 ,          #lambdaA for cycle loss\n",
    "    'lambdaB':10  ,         #lambdaB for cycle loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeInverse(transforms.Normalize):\n",
    "    \n",
    "    def __init__(self,mean,std):\n",
    "        \n",
    "        mean = torch.as_tensor(mean)\n",
    "        std = torch.as_tensor(std)\n",
    "        \n",
    "        std_inv = 1/(std+1e-7)\n",
    "        mean_inv = -mean*std_inv\n",
    "        super().__init__(mean=mean_inv,std=std_inv)\n",
    "        \n",
    "    def __call__(self,tensor):\n",
    "        return super().__call__(tensor.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_result(real_image, gen_image, epoch, save=False,  show=True, fig_size=(12, 12)):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=fig_size)\n",
    "    \n",
    "    imgs = [to_np(real_image[0]), to_np(gen_image[0]),\n",
    "            to_np(real_image[1]), to_np(gen_image[1])]\n",
    "       \n",
    "    for ax, img in zip(axes.flatten(), imgs):\n",
    "        ax.axis('off')\n",
    "        \n",
    "        img1=img[0,0,:,:,:]\n",
    "        img2=torch.from_numpy(img1)\n",
    "\n",
    "        tra=NormalizeInverse(mean=[0.5],std=[0.5])\n",
    "\n",
    "        img3 = tra(img2)*255\n",
    "        img3 = img3.to(dtype=torch.uint8)\n",
    "        \n",
    "        ax.imshow(img1[:,:,params['print_layer']], cmap='gray', aspect='equal')\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    title = 'Epoch {0}'.format(epoch + 1)\n",
    "    fig.text(0.5, 0.04, title, ha='center')\n",
    "\n",
    "    # save figure\n",
    "    if save:\n",
    "        save_fn = './ResultsFiles/Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_result29(recon_image29, epoch, save=False,  show=True, fig_size=(5, 15)):\n",
    "    \n",
    "    img = recon_image29\n",
    "    \n",
    "    plt.axis('off')\n",
    "        \n",
    "    img1=img[0,0,:,:]\n",
    "\n",
    "    img1 = to_np(img1)\n",
    "        \n",
    "    plt.imshow(img1, cmap='gray', aspect='equal')\n",
    "\n",
    "    title = 'Epoch {0}'.format(epoch + 1)\n",
    "\n",
    "    if save:\n",
    "        save_fn = './ResultsFiles/Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(im_list, save_dir, epoch_num, save_mode_on=True):\n",
    "    \"\"\"\n",
    "        Pytorch conv2d uses input & output dimensions as: (N, C, H, W).\n",
    "        To be able to plot the generated images, torch tensors must be converted back to (W,H,C)\n",
    "        and transferred back into the local memory by .cpu() function\n",
    "    \"\"\"\n",
    "\n",
    "    #A list that holds the necessary plot titles\n",
    "    titles = ['Real-Blur', 'Fake-Sharp (B->S)', 'Recon-Blur (B->S->B)', 'Identity-Sharp (S->S)']\n",
    "\n",
    "    im_idx = 0\n",
    "    fig, axarr = plt.subplots(1,4, figsize=(12, 12))\n",
    "\n",
    "    for j in range(4):\n",
    "\n",
    "        im = im_list[im_idx].squeeze().T\n",
    "        im = (im + 1) / 2.0\n",
    "        imm=im[params['print_layer'],:,:]\n",
    "        axarr[j].axis('off')\n",
    "        axarr[j].imshow(imm.detach().cpu())\n",
    "        axarr[j].set_title(titles[im_idx], fontweight=\"bold\")\n",
    "\n",
    "        im_idx = im_idx + 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_mode_on:\n",
    "        plt.savefig(os.path.join(save_dir, 'epoch-{}.png'.format(epoch_num)))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMyData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, subfolder='train', transform=None, crop_size=None, fliplr=False):\n",
    "        super(GetMyData, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        imgnpz = np.load(img_fn, mmap_mode='r', allow_pickle=True)\n",
    "        image = imgnpz['arr_0']\n",
    "        \n",
    "        #Preprocessing\n",
    "        #img = numpy.array(img)\n",
    "        imarray = numpy.array(image)\n",
    "        iim=image\n",
    "        \n",
    "        #Preprocessing\n",
    "        \n",
    "        if self.crop_size:\n",
    "            \n",
    "            x = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            y = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            \n",
    "            #iim = im.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
    "            \n",
    "            iim=torch.from_numpy(imarray)\n",
    "            iim=iim[x:x + self.crop_size,y:y+ self.crop_size,:]\n",
    "\n",
    "            \n",
    "    \n",
    "        if self.transform is not None:\n",
    "            iim=torch.from_numpy(imarray)\n",
    "            \n",
    "            aaa=imarray[:,:,0]\n",
    "            aaa0 = self.transform(aaa)\n",
    "               \n",
    "            iim = aaa0[...,np.newaxis]\n",
    "\n",
    "            for i in range (1,params['stack_num']):   \n",
    "                 \n",
    "                aaa=imarray[:,:,i]\n",
    "                aaa1 = self.transform(aaa)\n",
    "               \n",
    "                aaa1 = aaa1[...,np.newaxis]\n",
    "                iim=np.concatenate((iim,aaa1),3)\n",
    "\n",
    "        return iim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetVerticalData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, subfolder='train', transform=None,crop_size=None, fliplr=False):\n",
    "        super(GetVerticalData, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "     \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn)\n",
    "        \n",
    "        imarray = numpy.array(img)\n",
    "        imm=imarray\n",
    "        \n",
    "        if self.crop_size:\n",
    "            \n",
    "            imm = torch.from_numpy(imarray)\n",
    "            \n",
    "            x = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            y = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            \n",
    "            imm = imm[x:x + self.crop_size,y:y + self.crop_size]\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            \n",
    "            imm = self.transform(imarray)\n",
    "\n",
    "        return imm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetSharpData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, subfolder='train', transform=None,crop_size=None, fliplr=False):\n",
    "        super(GetSharpData, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "     \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn)\n",
    "        \n",
    "        imarray = numpy.array(img)\n",
    "        imm=imarray\n",
    "        \n",
    "        if self.crop_size:\n",
    "            \n",
    "            imm = torch.from_numpy(imarray)\n",
    "            x = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            imm = imm[x:x+ self.crop_size,:]\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            \n",
    "            imm = self.transform(imarray)\n",
    "\n",
    "        return imm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetVerticalData_scale(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, subfolder='train', transform=None):\n",
    "        super(GetVerticalData_new, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "     \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn)\n",
    "        \n",
    "        imarray = numpy.array(img)  \n",
    "        imarray = imarray[:,11:18]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            \n",
    "            imarray = torch.from_numpy(imarray)\n",
    "            imarray = self.transform(imarray)\n",
    "\n",
    "        return imarray\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicationPad3d(torch.nn.modules.padding._ReplicationPadNd):\n",
    "    def __init__(self, padding):\n",
    "        super(ReplicationPad3d, self).__init__()\n",
    "        self.padding = _ntuple(6)(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(torch.nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self,features_Nr,kernel_size=3,stride=1,padding=1,downsample=None):\n",
    "        super(ResnetBlock,self).__init__()\n",
    "        \n",
    "        self.conv1=torch.nn.Conv3d(features_Nr, features_Nr, kernel_size,stride,padding)\n",
    "        self.Bn1=torch.nn.BatchNorm3d(features_Nr)\n",
    "        self.LRe1=torch.nn.LeakyReLU(0.2)\n",
    "            \n",
    "        self.conv2=torch.nn.Conv3d(features_Nr,features_Nr,  kernel_size,stride,padding)\n",
    "        self.Bn2=torch.nn.BatchNorm3d(features_Nr)\n",
    "        self.LRe2=torch.nn.LeakyReLU(0.2)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual=x\n",
    "        output=self.conv1(x)\n",
    "        output=self.Bn1(output)\n",
    "        output=self.LRe1(output)\n",
    "        output=self.conv2(output)\n",
    "        output=self.Bn2(output)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        output=output+residual\n",
    "        \n",
    "        output=self.LRe2(output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,bias=False,padding=1,activation='relu',batch_norm=True):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(input_size,output_size,kernel_size,stride,padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm3d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock2d(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n",
    "        super(ConvBlock2d,self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,bias=False,padding=1,output_padding=1,activation='relu',batch_norm=True):\n",
    "        super(DeconvBlock,self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose3d(input_size,output_size,kernel_size,stride,padding,output_padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm3d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,num_filter,output_dim,num_resnet):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        #Reflection padding\n",
    "        self.pad1 = ReplicationPad3d(3)\n",
    "        self.pad2 = ReplicationPad3d(2)\n",
    "        \n",
    "        #Encoder\n",
    "        #self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=(7,7,7),stride=1,padding=(2,2,2),activation='relu',batch_norm=True)\n",
    "        self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=5,stride=1,padding=2,activation='relu',batch_norm=True)\n",
    "        self.conv2 = ConvBlock(num_filter,num_filter*2,activation='relu',batch_norm=True)\n",
    "        self.conv3 = ConvBlock(num_filter*2,num_filter*4,activation='relu',batch_norm=True)\n",
    "        \n",
    "        #Resnet blocks\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(num_resnet):\n",
    "            self.resnet_blocks.append(ResnetBlock(num_filter*4))\n",
    "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
    "        \n",
    "        #Decoder\n",
    "        self.deconv1 = DeconvBlock(num_filter*4,num_filter*2,activation='relu',batch_norm=True)\n",
    "        self.deconv2 = DeconvBlock(num_filter*2,num_filter,activation='relu',batch_norm=True)\n",
    "        ##self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=(7,7,6),stride=1,bias=True,padding=(2,2,2),activation='tanh',batch_norm=False)\n",
    "        self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=(5,5,6),stride=1,padding=(2,2,1),activation='tanh',batch_norm=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Encoder\n",
    "        #enc0=self.pad1(x)\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        \n",
    "        \n",
    "        #Resnet blocks\n",
    "        #res0 = self.pad2(enc3)\n",
    "        \n",
    "        res=self.resnet_blocks(enc3)\n",
    "      \n",
    "        #Decoder\n",
    "        #dec0=self.pad2(res)\n",
    "        dec1 = self.deconv1(res)\n",
    "        dec2 = self.deconv2(dec1)\n",
    "        ##dec3 = self.pad2(dec2)\n",
    "        out = self.deconv3(dec2)\n",
    "\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "            if isinstance(m,DeconvBlock):\n",
    "                torch.nn.init.normal_(m.deconv.weight,mean,std)\n",
    "            if isinstance(m,ResnetBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "                torch.nn.init.constant_(m.conv.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,input_dim,num_filter,output_dim):\n",
    "        super(Discriminator,self).__init__()\n",
    "        conv1 = ConvBlock2d(input_dim,num_filter,kernel_size=4,stride=2,padding=1,activation='lrelu',batch_norm=False)\n",
    "        conv2 = ConvBlock2d(num_filter,num_filter*2,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv3 = ConvBlock2d(num_filter*2,num_filter*4,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv4 = ConvBlock2d(num_filter*4,num_filter*8,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv5 = ConvBlock2d(num_filter*8,output_dim,kernel_size=2,stride=1,padding=1,activation='no_act',batch_norm=False)\n",
    "        self.conv_blocks = torch.nn.Sequential(\n",
    "            conv1,\n",
    "            conv2,\n",
    "            conv3,\n",
    "            conv4,\n",
    "            conv5\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.conv_blocks(x)\n",
    "        return out\n",
    "        \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight.data,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(params['input_size'],params['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform29 = transforms.Compose([transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(params['input_size'],params['stack_num'])),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for linux or Mac os\n",
    "def manage_folders():\n",
    "\n",
    "    currentDT = datetime.datetime.now().strftime(\"%Y_%m_%d-%H:%M\")\n",
    "\n",
    "    #cur_dir='D:/'\n",
    "    #for windows\n",
    "    cur_dir = os.getcwd()\n",
    "\n",
    "    if not os.path.isdir(os.path.join(cur_dir, 'Output')):\n",
    "        os.mkdir(os.path.join(cur_dir, 'Output'))\n",
    "\n",
    "    output_folder = os.path.join(cur_dir, 'Output')\n",
    "    output_folder = os.path.join(output_folder, currentDT)\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "    graph_save_dir = os.path.join(output_folder, 'loss-graphs')\n",
    "    if not os.path.isdir(graph_save_dir):\n",
    "        os.mkdir(graph_save_dir)\n",
    "\n",
    "    im_save_dir = os.path.join(output_folder, 'generated-images')\n",
    "    if not os.path.isdir(im_save_dir):\n",
    "        os.mkdir(im_save_dir)\n",
    "\n",
    "    tr_im_save_dir = os.path.join(im_save_dir, 'train')\n",
    "    if not os.path.isdir(tr_im_save_dir):\n",
    "        os.mkdir(tr_im_save_dir)\n",
    "\n",
    "    te_im_save_dir = os.path.join(im_save_dir, 'te')\n",
    "    if not os.path.isdir(te_im_save_dir):\n",
    "        os.mkdir(te_im_save_dir)\n",
    "\n",
    "    model_save_dir = os.path.join(output_folder, 'saved-models')\n",
    "    if not os.path.isdir(model_save_dir):\n",
    "        os.mkdir(model_save_dir)\n",
    "\n",
    "    # Check if the directories exist\n",
    "    assert(os.path.isdir(im_save_dir)), 'Check your im_save_dir path.'\n",
    "    assert(os.path.isdir(graph_save_dir)), 'Check your graph_save_dir path.'\n",
    "\n",
    "    print('-----Directories to save the output-----\\nTrain Fake Images: {}\\nVal Fake Images: {}\\nLosses: {}\\nModel: {}'.format(tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir))\n",
    "\n",
    "    return tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_S = GetSharpData(data_dir, subfolder='trainA2D', transform=transform,crop_size=params['crop_size'])\n",
    "train_data_loader_S = torch.utils.data.DataLoader(dataset=train_data_S, batch_size=1, shuffle=True)\n",
    "\n",
    "train_data_B = GetMyData(data_dir, subfolder='trainB', transform=transform,crop_size=params['crop_size'])\n",
    "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=1, shuffle=True)\n",
    "\n",
    "test_data_S = GetSharpData(data_dir, subfolder='testA2D', transform=transform,crop_size=params['crop_size'])\n",
    "test_data_loader_S = torch.utils.data.DataLoader(dataset=test_data_S, batch_size=1, shuffle=False)\n",
    "\n",
    "test_data_B = GetMyData(data_dir, subfolder='testB', transform=transform,crop_size=params['crop_size'])\n",
    "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=1, shuffle=False)\n",
    "\n",
    "train29_data_S = GetVerticalData(data_dir, subfolder='trainA29', transform=transform29,crop_size=params['crop_size'])\n",
    "train29_data_loader_S = torch.utils.data.DataLoader(dataset=train29_data_S, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "test29_data_S = GetVerticalData(data_dir, subfolder='testA29', transform=transform29,crop_size=params['crop_size'])\n",
    "test29_data_loader_S = torch.utils.data.DataLoader(dataset=test29_data_S, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_Loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "D_B2S_avg_losses = []\n",
    "D29_B2S_avg_losses = []\n",
    "D_S2B_avg_losses = []\n",
    "\n",
    "G_B2S_avg_losses = []\n",
    "G_S2B_avg_losses = []\n",
    "cycle_B2S_avg_losses = []\n",
    "cycle_S2B_avg_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pool = 50\n",
    "fake_B2S_pool = ImagePool(num_pool)\n",
    "fake29_B2S_pool=ImagePool(num_pool)\n",
    "fake_S2B_pool = ImagePool(num_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(inputs, is_real):\n",
    "\n",
    "    if is_real:\n",
    "\n",
    "        return F.mse_loss(inputs, torch.ones(inputs.shape).to(device))\n",
    "    else:\n",
    "        return F.mse_loss(inputs, torch.zeros(inputs.shape).to(device))\n",
    "    \n",
    "    \n",
    "def gan_loss_max(inputs, is_real):\n",
    "\n",
    "    if is_real:\n",
    "        \n",
    "        G_loss = F.mse_loss(inputs[:,:,:,:,0], torch.ones(inputs[:,:,:,:,0].shape).to(device))\n",
    "    \n",
    "        for i in range(1,params['stack_num']):\n",
    "            \n",
    "            G_lossi = F.mse_loss(inputs[:,:,:,:,i], torch.ones(inputs[:,:,:,:,i].shape).to(device))   \n",
    "            G_loss = max(G_loss,G_lossi)       \n",
    "\n",
    "        return G_loss\n",
    "    \n",
    "    else:\n",
    "        G_loss = F.mse_loss(inputs[:,:,:,:,0], torch.zeros(inputs[:,:,:,:,0].shape).to(device))\n",
    "    \n",
    "        for i in range(1,params['stack_num']):\n",
    "            \n",
    "            G_lossi = F.mse_loss(inputs[:,:,:,:,i], torch.zeros(inputs[:,:,:,:,i].shape).to(device))   \n",
    "            G_loss = max(G_loss,G_lossi)\n",
    "        return G_loss\n",
    "\n",
    "    \n",
    "def cycle_loss_original(reconstructed_images, real_images):\n",
    "\n",
    "    return F.l1_loss(reconstructed_images, real_images)\n",
    "\n",
    "\n",
    "def cycle_loss_weighted(reconstructed_images, real_images,p_similarity):\n",
    "\n",
    "    C_loss = F.l1_loss(reconstructed_images[:,:,:,:,0], real_images[:,:,:,:,0])*p_similarity[0]\n",
    "    \n",
    "    for i in range(1,params['stack_num']):\n",
    "        \n",
    "         C_loss = C_loss+F.l1_loss(reconstructed_images[:,:,:,:,i], real_images[:,:,:,:,i])*p_similarity[i]\n",
    "        \n",
    "    return C_loss/params['stack_num']\n",
    "\n",
    "\n",
    "def cycle_loss(reconstructed_images, real_images,p_similarity):\n",
    "\n",
    "    C_loss = F.l1_loss(reconstructed_images[:,:,:,:,0], real_images[:,:,:,:,0])*p_similarity[0]\n",
    "    \n",
    "    for i in range(1,params['stack_num']):\n",
    "        \n",
    "        C_lossi = F.l1_loss(reconstructed_images[:,:,:,:,i], real_images[:,:,:,:,i])*p_similarity[i]    \n",
    "        C_loss = max(C_loss,C_lossi)        \n",
    "        \n",
    "    return C_loss\n",
    "    \n",
    "\n",
    "def identity_loss(inputs, real_images):\n",
    "\n",
    "    return F.l1_loss(inputs, real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(sigma,mu, x):\n",
    "\n",
    "    k = 1 / (sigma * math.sqrt(2*math.pi))\n",
    "    s = -1.0 / (2 * sigma * sigma)\n",
    "    G = k * math.exp(s * (x - mu)*(x - mu))\n",
    "    \n",
    "    return  round(G*3.4+0.1,2)\n",
    "\n",
    "anisotropic=numpy.ones(params['stack_num'])\n",
    "n=(params['stack_num']+1)/2\n",
    "n=int(n)\n",
    "\n",
    "\n",
    "for i in range(0,n):\n",
    "    anisotropic[i]=round(gaussian(1.6,0,0.2*i),2)+0.72\n",
    "\n",
    "for i in range(n,params['stack_num']):\n",
    "    anisotropic[i]=round(gaussian(1.6,0,0.2*(params['stack_num']-1-i)),2)+0.72\n",
    "    \n",
    "\n",
    "similarity=numpy.ones(params['stack_num'])\n",
    "\n",
    "for i in range(0,n):\n",
    "    similarity[i]=gaussian(0.46,0,0.05*i)\n",
    "    \n",
    "for i in range(n,params['stack_num']):\n",
    "    N=(params['stack_num']-1)/2\n",
    "    similarity[i]=round(gaussian(0.45,0,0.05*(params['stack_num']-1-i))-0.01*(i-N),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cycleGAN(nn.Module):\n",
    "\n",
    "    def __init__(self, learning_rate=2e-4):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        #params['input_size']\n",
    "        \n",
    "        #Loss function coeffs\n",
    "        self.LAMBDA_CYCLE = 10.5\n",
    "        self.LAMBDA_ID = 0.5\n",
    "        self.LAMBDA_CROSS = 0.35   #0.3works\n",
    "        \n",
    "        \n",
    "        self.counter = 0;\n",
    "        self.counter1 = 0;\n",
    "        self.progress = []\n",
    "        self.progress1 = []\n",
    "        \n",
    "        #Image pool parameter\n",
    "        pool_size = 50\n",
    "\n",
    "        #Discriminate test and train behaviour\n",
    "        self.is_training = True\n",
    "        self.save_losses = False\n",
    "\n",
    "        #Initialize the image pools for both domains.\n",
    "        self.fake_S_pool = ImagePool(pool_size)\n",
    "        self.fake_B_pool = ImagePool(pool_size)\n",
    "        self.fake29_S_pool = ImagePool(pool_size)\n",
    "\n",
    "        #Create dictionaries to save the entire loss progress\n",
    "        \n",
    "        self.tr_gen_loss_dict = {\n",
    "            'loss_gen_S2B': [],\n",
    "            'loss_gen_B2S': [],\n",
    "            \n",
    "            'loss_iden_S2B': [],\n",
    "            'loss_iden_B2S': [],\n",
    "            \n",
    "            'loss_cycle_B2S2B': [],\n",
    "            'loss_gen_total': []\n",
    "        }\n",
    "        self.tr_dis_loss_dict = {\n",
    "            'loss_dis_B': [],\n",
    "            'loss_dis_S': [],\n",
    "            'loss_dis_total': []\n",
    "        }\n",
    "        self.te_gen_loss_dict = {\n",
    "            'loss_gen_S2B': [],\n",
    "            'loss_gen_B2S': [],\n",
    "            \n",
    "            'loss_iden_S2B': [],\n",
    "            'loss_iden_B2S': [],\n",
    "            \n",
    "            'loss_cycle_B2S2B': [],\n",
    "            'loss_gen_total': []\n",
    "        }\n",
    "        self.te_dis_loss_dict = {\n",
    "            'loss_dis_B': [],\n",
    "            'loss_dis_S': [],\n",
    "            'loss_dis_total': []\n",
    "        }\n",
    "\n",
    "        self.im_list = []\n",
    "\n",
    "        self.generator_S2B = Generator(1,params['ngf'],1,params['num_resnet'])\n",
    "        self.generator_B2S = Generator(1,params['ngf'],1,params['num_resnet'])\n",
    "        \n",
    "        self.discriminator_S = Discriminator(1,params['ndf'],1)\n",
    "        self.discriminator_B = Discriminator(1,params['ndf'],1)\n",
    "        \n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.generator_S2B.parameters(), self.generator_B2S.parameters()), lr=self.learning_rate)\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.discriminator_S.parameters(), self.discriminator_B.parameters()), lr=self.learning_rate)\n",
    "                  \n",
    "        \n",
    "\n",
    "    def forward(self, real_B):\n",
    "\n",
    "        fake_B2S = self.generator_B2S(real_B)\n",
    "        fake_S2B = self.generator_S2B(fake_B2S)\n",
    "        recon_S2B = fake_S2B\n",
    "        #recon_S2B = self.generator_S2B(fake_B2S)\n",
    "        \n",
    "        jj = random.randint(0,params['input_size']-1)\n",
    "        fake29_B2S=fake_B2S[:,:,jj,:,:]\n",
    "\n",
    "        identity_S2B = self.generator_S2B(real_B)\n",
    "        identity_B2S = self.generator_B2S(fake_B2S)\n",
    "\n",
    "        self.im_list = [real_B,fake_B2S,recon_S2B,identity_B2S]\n",
    "\n",
    "        return fake_S2B, recon_S2B,fake_B2S,identity_S2B,identity_B2S,fake29_B2S\n",
    "    \n",
    "\n",
    "    def backward_G(self, real_B, fake_S2B, fake_B2S, recon_S2B, identity_S2B, identity_B2S, fake29_B2S):\n",
    "        \n",
    "        if self.is_training:\n",
    "          \n",
    "            self.set_requires_grad([self.discriminator_B,self.discriminator_S], False)\n",
    "      \n",
    "            self.optimizer_G.zero_grad()\n",
    "\n",
    "        loss_identity_S2B = identity_loss(identity_S2B, real_B)\n",
    "        loss_identity_B2S = identity_loss(identity_B2S, fake_B2S)\n",
    "                                            \n",
    "        ii0= random.randint(0,params['stack_num']-1)                                    \n",
    "        loss_gan_gen_S2B = anisotropic[ii0]*gan_loss(self.discriminator_B(fake_S2B[:,:,:,:,ii0]), True)\n",
    "        \n",
    "        jj= random.randint(0,params['input_size']-1)\n",
    "        ii= random.randint(0,params['stack_num']-1)\n",
    "        pp= random.randint(0,1)\n",
    "        loss_gan_gen_B2S = anisotropic[ii]*(1-self.LAMBDA_CROSS)*gan_loss(self.discriminator_S(fake_B2S[:,:,:,:,ii]), True) + self.LAMBDA_CROSS *0.5*pp*gan_loss(self.discriminator_S(fake_B2S[:,:,jj,:,:]), True)+self.LAMBDA_CROSS *0.5*(1-pp)*gan_loss(self.discriminator_S(fake_B2S[:,:,:,jj,:]), True)\n",
    "                                                                          \n",
    "        loss_cycle_B2S2B = cycle_loss(recon_S2B, real_B, similarity)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_gen_total = loss_gan_gen_S2B + loss_gan_gen_B2S \\\n",
    "            + loss_cycle_B2S2B * self.LAMBDA_CYCLE \\\n",
    "            + (loss_identity_S2B+loss_identity_B2S) * self.LAMBDA_ID\n",
    "        \n",
    "        loss_plot=loss_gen_total\n",
    "        loss_plot1=loss_gan_gen_S2B\n",
    "        loss_plot2=loss_gan_gen_B2S\n",
    "        loss_plot3=loss_cycle_B2S2B\n",
    "        \n",
    "        self.counter += 1;\n",
    "        \n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss_plot.item())\n",
    "            self.progress.append(loss_plot1.item())\n",
    "            self.progress.append(loss_plot2.item())\n",
    "            self.progress.append(loss_plot3.item())\n",
    "            pass\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        if self.is_training:\n",
    "            # Calculate gradients\n",
    "            loss_gen_total.backward()\n",
    "\n",
    "            self.optimizer_G.step()\n",
    "\n",
    "\n",
    "        if self.save_losses:\n",
    "            if self.is_training:\n",
    "                self.tr_gen_loss_dict['loss_gen_S2B'].append(loss_gan_gen_S2B.item())\n",
    "                self.tr_gen_loss_dict['loss_gen_B2S'].append(loss_gan_gen_B2S.item())\n",
    "                self.tr_gen_loss_dict['loss_iden_S2B'].append(loss_identity_S2B.item())\n",
    "                \n",
    "                self.tr_gen_loss_dict['loss_cycle_B2S2B'].append(loss_cycle_B2S2B.item())\n",
    "                self.tr_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
    "            else:\n",
    "                self.te_gen_loss_dict['loss_gen_S2B'].append(loss_gan_gen_S2B.item())\n",
    "                self.te_gen_loss_dict['loss_gen_B2S'].append(loss_gan_gen_B2S.item())\n",
    "                self.te_gen_loss_dict['loss_iden_S2B'].append(loss_identity_S2B.item())\n",
    "           \n",
    "                self.te_gen_loss_dict['loss_cycle_B2S2B'].append(loss_cycle_B2S2B.item())\n",
    "                self.te_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
    "\n",
    "\n",
    "\n",
    "    def backward_D(self, real_S, real_B, fake_S2B, fake_B2S,real29_S,fake29_B2S):\n",
    "\n",
    "        fake_S2B = self.fake_B_pool.query(fake_S2B)\n",
    "        fake_B2S = self.fake_S_pool.query(fake_B2S)\n",
    "        fake29_B2S = self.fake29_S_pool.query(fake29_B2S)\n",
    "\n",
    "        if self.is_training:\n",
    "            self.set_requires_grad([self.discriminator_B,self.discriminator_S], True)\n",
    "            self.optimizer_D.zero_grad()  \n",
    "\n",
    "        loss_gan_dis_S_real = (1-self.LAMBDA_CROSS)*gan_loss(self.discriminator_S(real_S), True)+self.LAMBDA_CROSS *gan_loss(self.discriminator_S(real29_S), True)\n",
    "      \n",
    "        jj = random.randint(0,params['input_size']-1)\n",
    "        ii = random.randint(0,params['stack_num']-1)\n",
    "        pp = random.randint(0,1)\n",
    "        loss_gan_dis_S_fake = anisotropic[ii]*(1-self.LAMBDA_CROSS)*gan_loss(self.discriminator_S(fake_B2S[:,:,:,:,ii].detach()), False)+ self.LAMBDA_CROSS*0.5*pp*gan_loss(self.discriminator_S(fake_B2S[:,:,jj,:,:].detach()), False)+ self.LAMBDA_CROSS*0.5*(1-pp)*gan_loss(self.discriminator_S(fake_B2S[:,:,:,jj,:].detach()), False) # Detach added\n",
    "                                  \n",
    "        # Discriminator B should classify real_b as B\n",
    "        ii = random.randint(0,params['stack_num']-1)                                                    \n",
    "        loss_gan_dis_B_real =anisotropic[ii]* gan_loss(self.discriminator_B(real_B[:,:,:,:,ii]), True)\n",
    "        # Discriminator B should classify generated fake_a2b as not B\n",
    "        ii = random.randint(0,params['stack_num']-1)\n",
    "        loss_gan_dis_B_fake = anisotropic[ii]*gan_loss(self.discriminator_B(fake_S2B[:,:,:,:,ii].detach()), False) # Detach added\n",
    "                                            \n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_dis_S = (loss_gan_dis_S_real + loss_gan_dis_S_fake) * 0.5\n",
    "        \n",
    "        loss_dis_B = (loss_gan_dis_B_real + loss_gan_dis_B_fake) * 0.5\n",
    "\n",
    "        loss_dis_total = loss_dis_S + loss_dis_B\n",
    "        \n",
    "        loss_plott=loss_dis_total\n",
    "        loss_plott1=loss_dis_S\n",
    "        loss_plott2=loss_dis_B\n",
    "        \n",
    "        \n",
    "        self.counter1 += 1;\n",
    "        \n",
    "        if (self.counter1 % 10 == 0):\n",
    "            self.progress1.append(loss_plott.item())\n",
    "            self.progress1.append(loss_plott1.item())\n",
    "            self.progress1.append(loss_plott2.item())\n",
    "\n",
    "            pass\n",
    "        if (self.counter1 % 1000 == 0):\n",
    "            print(\"counter1 = \", self.counter1)\n",
    "            pass\n",
    "\n",
    "\n",
    "        if self.is_training:\n",
    "            # Calculate gradients\n",
    "            loss_dis_total.backward()\n",
    "            # Update D_A and D_B's weights\n",
    "            self.optimizer_D.step()\n",
    "\n",
    "        # Save train and test losses separately\n",
    "        if self.save_losses:\n",
    "            if self.is_training:\n",
    "                self.tr_dis_loss_dict['loss_dis_B'].append(loss_dis_B.item())\n",
    "                self.tr_dis_loss_dict['loss_dis_S'].append(loss_dis_S.item())\n",
    "                self.tr_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
    "            else:\n",
    "                self.te_dis_loss_dict['loss_dis_B'].append(loss_dis_B.item())\n",
    "                self.te_dis_loss_dict['loss_dis_S'].append(loss_dis_S.item())\n",
    "                self.te_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
    "\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "      \n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "                    \n",
    "                    \n",
    "    def plot_progress(self):\n",
    "        \n",
    "        df = pandas.DataFrame(self.progress, columns=['loss_plot'])\n",
    "        df1=pandas.concat([df, pandas.DataFrame(columns = [ 'loss_plot1'])])\n",
    "        df1=pandas.concat([df1, pandas.DataFrame(columns = [ 'loss_plot2'])])\n",
    "        df1=pandas.concat([df1, pandas.DataFrame(columns = [ 'loss_plot3'])])\n",
    "\n",
    "        fig,ax= plt.subplots()\n",
    "        \n",
    "        ax=df1[['loss_plot','loss_plot1','loss_plot2','loss_plot3']].plot.area(ax=ax)\n",
    "\n",
    "        ax.autoscale()\n",
    "        ax.set_ylim(0,None)\n",
    "        ax.margins(x=0)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def plot_progress1(self):\n",
    "        \n",
    "        df = pandas.DataFrame(self.progress1, columns=['loss_plott'])\n",
    "        df1=pandas.concat([df, pandas.DataFrame(columns = [ 'loss_plott1'])])\n",
    "        df1=pandas.concat([df1, pandas.DataFrame(columns = [ 'loss_plott2'])])\n",
    "        \n",
    "        fig,ax= plt.subplots()\n",
    "  \n",
    "        ax=df1[['loss_plott','loss_plott1','loss_plott2']].plot.area(ax=ax)\n",
    "\n",
    "        ax.autoscale()\n",
    "        ax.set_ylim(0,None)\n",
    "        ax.margins(x=0)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self, real_S, real_B,real29_S):\n",
    "\n",
    "        # Forward\n",
    "        fake_S2B, recon_S2B,fake_B2S,identity_S2B,identity_B2S,fake29_B2S = self.forward(real_B)  # compute fake images and reconstruction images.\n",
    "        # G_A and G_B\n",
    "        self.backward_G(real_B, fake_S2B, fake_B2S, recon_S2B, identity_S2B, identity_B2S, fake29_B2S)  # calculate gradients for G_A and G_B\n",
    "        # D_A and D_B\n",
    "        self.backward_D(real_S, real_B, fake_S2B, fake_B2S,real29_S,fake29_B2S)  # To-Do: Query fake images from the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset_S, train_dataset_B,test_dataset_S,test_dataset_B,train_dataset29_S,test_dataset29_S ,epochs, device):\n",
    " \n",
    "    model = cycleGAN().to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('Epoch', epoch+1, '------------------')\n",
    "        \n",
    "\n",
    "        #Training\n",
    "        temp = 1\n",
    "        model.is_training = True\n",
    "        \n",
    "        for i, (data_S, data_B,data29_S) in enumerate(zip(train_dataset_S,train_dataset_B,train_dataset29_S)):\n",
    "        \n",
    "            #Input image data\n",
    "            data_S = data_S.to(device)\n",
    "            data29_S = data29_S.to(device)\n",
    "            data_B = data_B.to(device)\n",
    "      \n",
    "\n",
    "            #Save loss values at the end of each epoch\n",
    "            if temp == train_dataset_S.__len__():\n",
    "                model.save_losses = True\n",
    "\n",
    "            model.optimize_parameters(data_S, data_B,data29_S)\n",
    "\n",
    "            temp = temp+1\n",
    "            \n",
    "        model.plot_progress()\n",
    "        model.plot_progress1()\n",
    "\n",
    "        print('Tr - Total Generator Loss:', np.round(model.tr_gen_loss_dict['loss_gen_total'][-1], decimals=3))\n",
    "        print('Tr - Total Dicriminator Loss:', np.round(model.tr_dis_loss_dict['loss_dis_total'][-1], decimals=3))\n",
    "\n",
    "        model.save_losses = False\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            \n",
    "            print_images(model.im_list, tr_im_save_dir, str(epoch), save_mode_on=True)\n",
    "\n",
    "        #Test\n",
    "        with torch.set_grad_enabled(False):\n",
    "\n",
    "            temp = 1\n",
    "            model.is_training = False\n",
    "            for i, (data_S, data_B,data29_S) in enumerate(zip(test_dataset_S,test_dataset_B,test_dataset29_S)):\n",
    "\n",
    "                data_S = data_S.to(device)\n",
    "                data29_S = data29_S.to(device)\n",
    "                data_B = data_B.to(device)\n",
    "\n",
    "                if temp == test_dataset_S.__len__():\n",
    "                    model.save_losses = True\n",
    "\n",
    "                model.optimize_parameters(data_S, data_B,data29_S)\n",
    "\n",
    "                temp = temp+1\n",
    "\n",
    "            print('----')\n",
    "            print('te - Total Generator Loss:', np.round(model.te_gen_loss_dict['loss_gen_total'][-1], decimals=3))\n",
    "            print('te - Total Dicriminator Loss:', np.round(model.te_dis_loss_dict['loss_dis_total'][-1], decimals=3))\n",
    "\n",
    "            model.save_losses = False\n",
    "\n",
    "            print_images(model.im_list, te_im_save_dir, str(epoch), save_mode_on=True)\n",
    "            \n",
    "            test_real_Blur = test_blur_data.cuda()\n",
    "    \n",
    "            Results = model.forward(test_real_Blur)\n",
    "    \n",
    "        \n",
    "            test_fake_Blur = Results[0]\n",
    "    \n",
    "            test_recon_Sharp = Results[4]\n",
    "    \n",
    "            test_fake_Sharp = Results[2]\n",
    "    \n",
    "            test_recon_Blur = Results[1]\n",
    "        \n",
    "            test_recon_Blur29 = Results[5]\n",
    "\n",
    "            ##plot_train_result([test_real_Blur, test_recon_Blur], [test_fake_Sharp, test_recon_Sharp],epoch, save=False)\n",
    "            plot_train_result29(test_recon_Blur29,epoch, save=False)\n",
    "            \n",
    "            if epoch  > params['save_epoch']:\n",
    "                torch.save(model,os.path.join(model_save_dir,'model_%03d.pth'%epoch))\n",
    "    \n",
    " \n",
    "    #Save gen and disc loss values to respective csv files.\n",
    "    df = pd.DataFrame.from_dict(model.tr_gen_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'tr_gen_losses.csv'), index=False)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(model.tr_dis_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'tr_dis_losses.csv'), index=False)\n",
    "    \n",
    "    #Save gen and disc loss values to respective csv files.\n",
    "    df = pd.DataFrame.from_dict(model.te_gen_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'te_gen_losses.csv'), index=False)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(model.te_dis_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'te_dis_losses.csv'), index=False)\n",
    "\n",
    "    #Save entire model architecture and params.\n",
    "    torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Directories to save the output-----\n",
      "Train Fake Images: /Users/Honglei/Output/2023_05_03-18:22/generated-images/train\n",
      "Val Fake Images: /Users/Honglei/Output/2023_05_03-18:22/generated-images/te\n",
      "Losses: /Users/Honglei/Output/2023_05_03-18:22/loss-graphs\n",
      "Model: /Users/Honglei/Output/2023_05_03-18:22/saved-models\n"
     ]
    }
   ],
   "source": [
    "tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir = manage_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_data_loader_S,train_data_loader_B,test_data_loader_S,test_data_loader_B,train29_data_loader_S,test29_data_loader_S,200, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
